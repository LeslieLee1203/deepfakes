{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "ZIblCmImlFto",
        "outputId": "7a37b600-b1cd-44b0-9226-8047786951ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#@markdown 下載 mnist 資料集\n",
        "\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(x_train, _ ), (x_test, _ ) = mnist.load_data()\n",
        "img_rows = 28\n",
        "img_cols = 28\n",
        "channels = 1\n",
        "\n",
        "img_shape = (img_rows, img_cols, channels)\n",
        "\n",
        "latent_dim = 100\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 建立 Discriminator\n",
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Flatten(input_shape=img_shape)) # (28,28,1)\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    model.summary()\n",
        "\n",
        "    img = Input(shape=img_shape)\n",
        "    validity = model(img)\n",
        "\n",
        "    return Model(img, validity)\n",
        "\n",
        "optimizer = Adam(0.0002, 0.5)\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "__9kGa-3lYIU",
        "outputId": "88ad272a-28da-49d8-db63-37ccf18620fd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               401920    \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 533,505\n",
            "Trainable params: 533,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 建立 Generator\n",
        "import numpy as np\n",
        "def build_generator():\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(256, input_dim=latent_dim)) # Noise : 100 -> 256\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dense(512)) # 256 -> 512\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dense(1024)) # 512 -> 1024\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dense(np.prod(img_shape), activation='tanh')) # 1024 -> 784(28 * 28)\n",
        "    model.add(Reshape(img_shape))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    noise = Input(shape=(latent_dim,))\n",
        "    img = model(noise)\n",
        "\n",
        "    return Model(noise, img)\n",
        "generator = build_generator()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "uN0Y3CsWr9Ll",
        "outputId": "a96fb072-7a46-4cbf-f22d-003f393af53d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 256)               25856     \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1024)              525312    \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 1024)              0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 1024)             4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 784)               803600    \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,493,520\n",
            "Trainable params: 1,489,936\n",
            "Non-trainable params: 3,584\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 合併模型\n",
        "z = Input(shape=(latent_dim,))\n",
        "img = generator(z)\n",
        "discriminator.trainable = False\n",
        "\n",
        "# The discriminator takes generated images as input and determines validity\n",
        "validity = discriminator(img)\n",
        "\n",
        "# The combined model  (stacked generator and discriminator)\n",
        "# Trains the generator to fool the discriminator\n",
        "combined = Model(z, validity)\n",
        "combined.compile(loss='binary_crossentropy', optimizer=optimizer)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cPoBZ4GcttZt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 模型訓練 \n",
        "from matplotlib import pyplot as plt\n",
        "def sample_images(epoch):\n",
        "    r, c = 5, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "    fig.savefig(\"/content/images/%d.png\" % epoch)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def train(epochs, batch_size=128, sample_interval=50):\n",
        "\n",
        "    # Load the dataset\n",
        "    (X_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "    # Rescale -1 to 1\n",
        "    X_train = X_train / 127.5 - 1.\n",
        "    X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "    # Adversarial ground truths\n",
        "    valid = np.ones((batch_size, 1))\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        # Select a random batch of images\n",
        "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "        imgs = X_train[idx]\n",
        "\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "\n",
        "        # Generate a batch of new images\n",
        "        gen_imgs = generator.predict(noise)\n",
        "\n",
        "        # Train the discriminator\n",
        "        d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
        "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "        # ---------------------\n",
        "        #  Train Generator\n",
        "        # ---------------------\n",
        "\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "\n",
        "        # Train the generator (to have the discriminator label samples as valid)\n",
        "        g_loss = combined.train_on_batch(noise, valid)\n",
        "\n",
        "        # Plot the progress\n",
        "        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "\n",
        "        # If at save interval => save generated image samples\n",
        "        if epoch % sample_interval == 0:\n",
        "            sample_images(epoch)\n",
        "\n",
        "! mkdir -p images\n",
        "train(100, batch_size=128, sample_interval=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "kVhkUg8csQSX",
        "outputId": "44f8216b-168b-4db3-95ea-b1e3c8db02d8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [D loss: 1.009383, acc.: 33.59%] [G loss: 0.887120]\n",
            "1 [D loss: 0.392441, acc.: 98.05%] [G loss: 0.859231]\n",
            "2 [D loss: 0.285669, acc.: 100.00%] [G loss: 0.820460]\n",
            "3 [D loss: 0.243812, acc.: 100.00%] [G loss: 0.809079]\n",
            "4 [D loss: 0.211200, acc.: 100.00%] [G loss: 0.761193]\n",
            "5 [D loss: 0.194744, acc.: 100.00%] [G loss: 0.762207]\n",
            "6 [D loss: 0.175779, acc.: 100.00%] [G loss: 0.729167]\n",
            "7 [D loss: 0.163766, acc.: 100.00%] [G loss: 0.703949]\n",
            "8 [D loss: 0.158668, acc.: 100.00%] [G loss: 0.656743]\n",
            "9 [D loss: 0.156205, acc.: 100.00%] [G loss: 0.647856]\n",
            "10 [D loss: 0.156333, acc.: 100.00%] [G loss: 0.657652]\n",
            "11 [D loss: 0.144244, acc.: 100.00%] [G loss: 0.659602]\n",
            "12 [D loss: 0.145239, acc.: 100.00%] [G loss: 0.676754]\n",
            "13 [D loss: 0.152088, acc.: 100.00%] [G loss: 0.688408]\n",
            "14 [D loss: 0.163287, acc.: 100.00%] [G loss: 0.669074]\n",
            "15 [D loss: 0.161134, acc.: 100.00%] [G loss: 0.679616]\n",
            "16 [D loss: 0.158633, acc.: 100.00%] [G loss: 0.709030]\n",
            "17 [D loss: 0.163302, acc.: 100.00%] [G loss: 0.785543]\n",
            "18 [D loss: 0.167819, acc.: 100.00%] [G loss: 0.791101]\n",
            "19 [D loss: 0.183898, acc.: 100.00%] [G loss: 0.894562]\n",
            "20 [D loss: 0.190057, acc.: 100.00%] [G loss: 0.929481]\n",
            "21 [D loss: 0.198467, acc.: 99.61%] [G loss: 1.091846]\n",
            "22 [D loss: 0.186711, acc.: 100.00%] [G loss: 1.150786]\n",
            "23 [D loss: 0.178650, acc.: 100.00%] [G loss: 1.315584]\n",
            "24 [D loss: 0.188573, acc.: 100.00%] [G loss: 1.425366]\n",
            "25 [D loss: 0.186661, acc.: 99.22%] [G loss: 1.574747]\n",
            "26 [D loss: 0.175765, acc.: 100.00%] [G loss: 1.802750]\n",
            "27 [D loss: 0.154166, acc.: 100.00%] [G loss: 1.939670]\n",
            "28 [D loss: 0.157691, acc.: 99.61%] [G loss: 2.101183]\n",
            "29 [D loss: 0.138949, acc.: 100.00%] [G loss: 2.234797]\n",
            "30 [D loss: 0.125086, acc.: 100.00%] [G loss: 2.455165]\n",
            "31 [D loss: 0.115604, acc.: 100.00%] [G loss: 2.637285]\n",
            "32 [D loss: 0.115590, acc.: 100.00%] [G loss: 2.786135]\n",
            "33 [D loss: 0.103686, acc.: 100.00%] [G loss: 2.885735]\n",
            "34 [D loss: 0.087065, acc.: 100.00%] [G loss: 3.053484]\n",
            "35 [D loss: 0.083526, acc.: 100.00%] [G loss: 3.017823]\n",
            "36 [D loss: 0.080496, acc.: 100.00%] [G loss: 3.148950]\n",
            "37 [D loss: 0.073255, acc.: 100.00%] [G loss: 3.248695]\n",
            "38 [D loss: 0.079191, acc.: 100.00%] [G loss: 3.346641]\n",
            "39 [D loss: 0.072185, acc.: 100.00%] [G loss: 3.389529]\n",
            "40 [D loss: 0.078902, acc.: 100.00%] [G loss: 3.628042]\n",
            "41 [D loss: 0.069331, acc.: 100.00%] [G loss: 3.674903]\n",
            "42 [D loss: 0.067665, acc.: 100.00%] [G loss: 3.817246]\n",
            "43 [D loss: 0.062538, acc.: 100.00%] [G loss: 3.868783]\n",
            "44 [D loss: 0.067015, acc.: 100.00%] [G loss: 4.007446]\n",
            "45 [D loss: 0.065194, acc.: 100.00%] [G loss: 3.988596]\n",
            "46 [D loss: 0.056289, acc.: 100.00%] [G loss: 4.111331]\n",
            "47 [D loss: 0.060798, acc.: 100.00%] [G loss: 4.244195]\n",
            "48 [D loss: 0.055074, acc.: 100.00%] [G loss: 4.350631]\n",
            "49 [D loss: 0.052539, acc.: 100.00%] [G loss: 4.423959]\n",
            "50 [D loss: 0.058193, acc.: 100.00%] [G loss: 4.402503]\n",
            "51 [D loss: 0.060602, acc.: 100.00%] [G loss: 4.454278]\n",
            "52 [D loss: 0.045185, acc.: 100.00%] [G loss: 4.526000]\n",
            "53 [D loss: 0.043961, acc.: 100.00%] [G loss: 4.511291]\n",
            "54 [D loss: 0.043987, acc.: 100.00%] [G loss: 4.583640]\n",
            "55 [D loss: 0.046202, acc.: 100.00%] [G loss: 4.577715]\n",
            "56 [D loss: 0.050759, acc.: 100.00%] [G loss: 4.490069]\n",
            "57 [D loss: 0.037577, acc.: 100.00%] [G loss: 4.764622]\n",
            "58 [D loss: 0.048918, acc.: 100.00%] [G loss: 4.722415]\n",
            "59 [D loss: 0.034709, acc.: 100.00%] [G loss: 4.602636]\n",
            "60 [D loss: 0.038882, acc.: 100.00%] [G loss: 4.561621]\n",
            "61 [D loss: 0.036162, acc.: 100.00%] [G loss: 4.499005]\n",
            "62 [D loss: 0.038471, acc.: 100.00%] [G loss: 4.677569]\n",
            "63 [D loss: 0.040135, acc.: 100.00%] [G loss: 4.590671]\n",
            "64 [D loss: 0.029601, acc.: 100.00%] [G loss: 4.541763]\n",
            "65 [D loss: 0.035659, acc.: 100.00%] [G loss: 4.508812]\n",
            "66 [D loss: 0.040481, acc.: 99.61%] [G loss: 4.607744]\n",
            "67 [D loss: 0.047362, acc.: 99.61%] [G loss: 4.509446]\n",
            "68 [D loss: 0.035744, acc.: 99.61%] [G loss: 4.399751]\n",
            "69 [D loss: 0.031782, acc.: 100.00%] [G loss: 4.641773]\n",
            "70 [D loss: 0.043869, acc.: 100.00%] [G loss: 4.645220]\n",
            "71 [D loss: 0.052314, acc.: 99.22%] [G loss: 4.639367]\n",
            "72 [D loss: 0.037228, acc.: 100.00%] [G loss: 4.673237]\n",
            "73 [D loss: 0.034546, acc.: 100.00%] [G loss: 4.581277]\n",
            "74 [D loss: 0.065313, acc.: 98.83%] [G loss: 4.567281]\n",
            "75 [D loss: 0.036893, acc.: 100.00%] [G loss: 4.833173]\n",
            "76 [D loss: 0.053674, acc.: 99.22%] [G loss: 4.783473]\n",
            "77 [D loss: 0.103430, acc.: 95.70%] [G loss: 4.928946]\n",
            "78 [D loss: 0.048833, acc.: 99.61%] [G loss: 4.962330]\n",
            "79 [D loss: 0.063751, acc.: 99.22%] [G loss: 4.946784]\n",
            "80 [D loss: 0.065457, acc.: 98.44%] [G loss: 5.004997]\n",
            "81 [D loss: 0.074154, acc.: 97.66%] [G loss: 4.737493]\n",
            "82 [D loss: 0.059569, acc.: 98.05%] [G loss: 4.545405]\n",
            "83 [D loss: 0.074227, acc.: 98.44%] [G loss: 5.007738]\n",
            "84 [D loss: 0.302774, acc.: 87.50%] [G loss: 4.787840]\n",
            "85 [D loss: 0.052671, acc.: 98.05%] [G loss: 5.278128]\n",
            "86 [D loss: 0.122175, acc.: 94.92%] [G loss: 5.072871]\n",
            "87 [D loss: 0.060428, acc.: 98.05%] [G loss: 5.215719]\n",
            "88 [D loss: 0.116919, acc.: 94.53%] [G loss: 4.630475]\n",
            "89 [D loss: 0.085208, acc.: 95.70%] [G loss: 5.222166]\n",
            "90 [D loss: 0.055554, acc.: 98.83%] [G loss: 4.941651]\n",
            "91 [D loss: 0.257341, acc.: 88.28%] [G loss: 4.465153]\n",
            "92 [D loss: 0.041697, acc.: 99.22%] [G loss: 4.618326]\n",
            "93 [D loss: 0.099599, acc.: 96.48%] [G loss: 4.915468]\n",
            "94 [D loss: 0.230825, acc.: 89.45%] [G loss: 4.599046]\n",
            "95 [D loss: 0.063658, acc.: 98.44%] [G loss: 4.926876]\n",
            "96 [D loss: 0.277517, acc.: 89.06%] [G loss: 4.292838]\n",
            "97 [D loss: 0.055906, acc.: 98.83%] [G loss: 4.858289]\n",
            "98 [D loss: 0.134097, acc.: 95.31%] [G loss: 4.277342]\n",
            "99 [D loss: 0.094143, acc.: 96.48%] [G loss: 4.690325]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 隨機產生圖片\n",
        "n1 = np.random.normal(0, 1, (1, 100))\n",
        "gen_imgs = generator.predict(n1)\n",
        "gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "plt.imshow(gen_imgs[0, :,:,0], cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "cellView": "form",
        "id": "ZB9_S27SsekE",
        "outputId": "0717aaca-adc6-4db2-96a6-3a36880e7c54"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe55b8858d0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}